{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import time \n",
    "import tracker\n",
    "import config\n",
    "os.chdir(config.LOOP_CATALOG_DIR)\n",
    "latest_date = tracker.processing_dates[-1]\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date='2024.1.16.10.52'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting input and output with jupyter notebook in context \n",
    "if 'ipykernel_launcher.py' in sys.argv[0]:\n",
    "    input_fn = 'results/samplesheets/hicpro/current.hicpro.samplesheet.without_header.tsv'.format(latest_date)\n",
    "    output_prefix = 'results/samplesheets/post-hicpro/{}.post-hicpro.post-check.fithichip-loop-calling'.format(latest_date)\n",
    "else:\n",
    "    input_fn = sys.argv[1]\n",
    "    output_fn = sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(\"results/biorep_merged/results/motif_analysis/meme/fimo/*/summarize_results/summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "    if os.path.getsize(p) <= 1:\n",
    "        print(p)\n",
    "    with open(p) as motifs:\n",
    "        count = 0\n",
    "        for line in motifs:\n",
    "            count +=1\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_log(log):\n",
    "    \n",
    "    status = 0\n",
    "    f_status = 0\n",
    "    sample_name = 'check'\n",
    "    peaks_found = 0\n",
    "    no_interact = 0\n",
    "    date = ''\n",
    "    config = ''\n",
    "    peak_type = ''\n",
    "\n",
    "     # extract job_id and index\n",
    "    meta = os.path.basename(log)\n",
    "    job_id = meta.split('-')[1].split('.')[0]\n",
    "    #job_id = meta[0].replace('o', '')\n",
    "    #index = meta[1]\n",
    "\n",
    "    with open(log, errors='ignore') as fr:\n",
    "        for line in fr:\n",
    "            info = line.strip()\n",
    "            if 'sample_name' in info:\n",
    "                sample_name = info.split()[1]\n",
    "            if 'peaks found and will be used to call loops' in info:\n",
    "                peaks_found = 1\n",
    "            if 'FitHiChIP pipeline is completely executed - congratulations !!!' in info:\n",
    "                f_status = 1\n",
    "            if 'SORRY !!!!!!!! FitHiChIP could not find any statistically significant interactions' in info:\n",
    "                no_interact = 1\n",
    "            if 'Ended: fithichip loop calling' in info:\n",
    "                status = 1\n",
    "            if 'Started: run_fithichip_loopcalling' in info:\n",
    "                config = info.split(\"_\")[3]\n",
    "            if 'Selected Peak Mode' in info:\n",
    "                mode = info.strip().split(\": \")[1]\n",
    "                if mode == \"2\":\n",
    "                    peak_type = \"fithichip\"\n",
    "                elif mode == \"3\":\n",
    "                    peak_type = \"chipseq\"\n",
    "                \n",
    "\n",
    "    return([sample_name, job_id, config, peak_type, peaks_found, no_interact, f_status, status])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_error_log(log):\n",
    "    \n",
    "    status = 1\n",
    "    eline = []\n",
    "    has_errors = 0\n",
    "    mem = 0\n",
    "    \n",
    "    with open(log, errors='ignore') as fr:\n",
    "        for line in fr:\n",
    "            info = line.strip()\n",
    "            if 'cat: /var/spool/torque/aux' in info:\n",
    "                continue\n",
    "            if 'Loading required package:' in info:\n",
    "                continue\n",
    "            if 'Attaching package:' in info:\n",
    "                continue\n",
    "            if 'The following objects are masked' in info:\n",
    "                continue\n",
    "            if line.startswith('\\t'):\n",
    "                continue\n",
    "            if 'The following object is masked' in info:\n",
    "                continue\n",
    "            if 'spar-finding: non-finite value inf; using BIG value' in info:\n",
    "                continue\n",
    "            if 'Warning message' in info:\n",
    "                continue\n",
    "            if line.startswith('\\n'):\n",
    "                continue\n",
    "            if 'cluster' in line:\n",
    "                continue\n",
    "            if 'par' in line:\n",
    "                continue\n",
    "            if 'IQR' in line or 'anyDuplicated' in line or 'dirname' in line or 'grepl' in line or 'order' in line or 'rbind' in line or 'union' in line or 'expand.grid' in line or 'shift' in line or 'first, second' in line:\n",
    "                continue\n",
    "            if 'containing missing values (geom_bar).' in line:\n",
    "                continue\n",
    "            if 'containing missing values (geom_path).' in line:\n",
    "                continue\n",
    "            if 'containing missing values (geom_point).' in line:\n",
    "                continue\n",
    "            if 'NaNs produced' in line:\n",
    "                continue\n",
    "            if 'In data.frame(group = paste(' in line:\n",
    "                continue\n",
    "            if 'aesthetic for lines was deprecated in ggplot2 3.4.0.' in line:\n",
    "                continue\n",
    "            if 'Please use `linewidth` instead.' in line:\n",
    "                continue\n",
    "            if 'Removed 2 rows containing missing values (`geom_bar()`).' in line:\n",
    "                continue\n",
    "            status = 0\n",
    "            eline.append(line)\n",
    "            if 'memory' in line:\n",
    "                mem = 1\n",
    "        if len(eline) != 0:\n",
    "            has_errors = 1\n",
    "            \n",
    "    return(status, eline, has_errors, mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_table(input_fn, skiprows=0, header = None)\n",
    "df['sample_index'] = df.index\n",
    "print('number of samples:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of log information, 506307, 508200, 5085036 (fixing mem errors), 50850 37-42 (hichip-peaks), 51014 (fithichip peaks)\n",
    "output_logs = glob.glob('results/biorep_merged/results/loops/logs/job-7145*.out')\n",
    "error_logs = glob.glob('results/biorep_merged/results/loops/logs/job-7145*.error')\n",
    "log_data = []   \n",
    "for out_log in output_logs: \n",
    "    sample_index = out_log.split('-')[1].split('.')[0]\n",
    "    sample_name, job_id, config, peak_type, peaks_found, no_interact, f_status, status = read_out_log(out_log)\n",
    "    error_log = [log for log in error_logs if log.split('-')[1].split('.')[0] == sample_index][0]\n",
    "    error_status, eline, has_errors, mem = read_error_log(error_log)\n",
    "    log_data.append([sample_name, job_id, config, peak_type, peaks_found, no_interact, f_status, status, error_status, eline, has_errors, mem, os.path.basename(out_log)])\n",
    "log_df = pd.DataFrame(log_data)\n",
    "log_df.columns = ['std_sample_name', 'job_id', 'config', 'peak_type', 'peaks_found', 'no_interact', 'f_status', 'out_status', 'error_status', 'errors', 'has_errors', 'mem', 'log']\n",
    "log_df = log_df.sort_values(by=[\"std_sample_name\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_df.sort_values(by=[\"std_sample_name\"], ascending=True).reset_index(drop=True)\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying problem samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "problems = (log_df.out_status == 0) | (log_df.error_status == 0) | (log_df.has_errors == 1)\n",
    "problems_df = log_df.loc[problems,:]\n",
    "print('number of problem samples:', len(problems_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "problems_df.loc[:, ['std_sample_name', 'job_id', 'config', 'peak_type', 'peaks_found', 'f_status', 'out_status', 'no_interact', 'error_status', 'errors', 'log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_df.loc[:, ['std_sample_name', 'job_id', 'config', 'peak_type', 'peaks_found', 'f_status', 'out_status', 'no_interact', 'error_status', 'errors', 'log']].loc[problems_df['config'] == \"S5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_df = problems_df.sort_values(by='std_sample_name').reset_index(drop=True)\n",
    "problems_df.to_excel(\"problems_biorepmerged.xlsx\", sheet_name='sample_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hichip-db-new",
   "language": "python",
   "name": "hichip-db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
